{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy KanjuTech Transcription and Speaker Diarization Model Package from AWS Marketplace \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "KanjuTech Transcription and Diarization model allows full end-to-end recognition of conversations with multiple participants, including cases with speech overlaps. The model utilizes GPU acceleration and allows the processing of a one-hour recording in less than 7.5 minutes. It supports 19 languages (WER<10%).\n",
    "\n",
    "This sample notebook shows you how to deploy [**KanjuTech Transcription and Diarization Model**](https://aws.amazon.com/marketplace/pp/prodview-ngtdx4ayt4emo?sr=0-1&ref_=beagle&applicationId=AWSMPContessa) using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [**KanjuTech Transcription and Diarization Model**](https://aws.amazon.com/marketplace/pp/prodview-ngtdx4ayt4emo?sr=0-1&ref_=beagle&applicationId=AWSMPContessa). If so, skip step: [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "\n",
    "## Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "The maximum audio file size for real-time inference is 20MB and for batch transform job is 100MB each file. The recommended duration of one audio file for real-time inference is limited to 7-8 minutes.\n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Subscribe to the model package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page [**KanjuTech Transcription and Diarization Model**](https://aws.amazon.com/marketplace/pp/prodview-ngtdx4ayt4emo?sr=0-1&ref_=beagle&applicationId=AWSMPContessa).\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_package_arn = \"<Specify Model package ARN corresponding to your AWS region>\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "import numpy as np\n",
    "import s3fs\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "#bucket = sagemaker_session.default_bucket() # use this line if you want to create default S3 bucket\n",
    "bucket = '<Name-of-your-existing-S3-bucket>' # write name of your S3 bucket where you store your input files and want to save the output\n",
    "runtime = boto3.client(\"runtime.sagemaker\")\n",
    "bucket"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Create an endpoint and perform real-time inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"kanjutech-transcription-speaker-diarization\"\n",
    "\n",
    "real_time_content_type = \"application/json\"\n",
    "batch_transform_content_type = \"audio/wav\"\n",
    "accept = \"application/json\"\n",
    "\n",
    "real_time_inference_instance_type = (\n",
    "    \"ml.g4dn.xlarge\"\n",
    ")\n",
    "batch_transform_inference_instance_type = (\n",
    "    \"ml.p3.2xlarge\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A. Create an endpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create a deployable model from the model package.\n",
    "model = ModelPackage(\n",
    "    role=role, model_package_arn=model_package_arn, sagemaker_session=sagemaker_session\n",
    ")\n",
    "\n",
    "# Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B. Create input payload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Input audio files from S3 bucket and encode in base64 (for endpoints). For real-time inference local-stored files can be used. \n",
    "The maximum audio file size for real-time inference is 20MB each file. The recommended duration of one audio file for real-time inference is limited to 7-8 minutes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "fs_ls = fs.ls(bucket+'/'+'<Your folder on S3 bucket where you store input audio>')\n",
    "paths = list(filter(lambda k: '.' in k, fs_ls))\n",
    "\n",
    "# We encode only one file from paths for example\n",
    "input_file_path = paths[0]\n",
    "\n",
    "with fs.open(input_file_path, \"rb\") as f:\n",
    "    edata = base64.b64encode(f.read())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create json file with encoded data, and additional parameters:\n",
    "'language': use \"auto\" for automatic language identification or \"en\": \"english\", \"ca\": \"catalan\", \"nl\": \"dutch\", \"fi\": \"finnish\", \"fr\": \"french\", \"de\": \"german\", \"id\": \"indonesian\", \"it\": \"italian\", \"ja\": \"japanese\", \"ms\": \"malay\", \"no\": \"norwegian\", \"pl\": \"polish\", \"pt\": \"portuguese\", \"ru\": \"russian\", \"es\": \"spanish\", \"sv\": \"swedish\", \"tr\": \"turkish\", \"uk\": \"ukrainian\", \"vi\": \"vietnamese\".\n",
    "'num_speakers': use \"auto\" for automatic identification of speakers or write a specific number"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "json_file = {}\n",
    "json_file['file'] = edata.decode('utf-8')\n",
    "json_file['language'] = \"en\"\n",
    "json_file['num_speakers'] = 2\n",
    "json_file['f_name'] = os.path.basename(input_file_path)\n",
    "data = json.dumps(json_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### C. Perform real-time inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Invoke the endpoint for real-time inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = runtime.invoke_endpoint(\n",
    "    EndpointName=model_name,\n",
    "    Body=data, \n",
    "    ContentType=real_time_content_type,  \n",
    "    Accept=accept,  \n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### D. Visualize output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(results['Body'].read().decode())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### E. Delete the endpoint"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.sagemaker_session.delete_endpoint(model_name)\n",
    "model.sagemaker_session.delete_endpoint_config(model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Perform batch inference"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upload input files to S3 for batch transform job. The maximum audio file size for batch transform job is 100MB each file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_input_folder = bucket+'/'+'<Your folder on S3 bucket where you store input audio>'\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or use your existing S3 bucket with input files"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform_input = bucket+'/'+'<Your folder on S3 bucket where you store input audio>'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run batch transform job"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Specify language and number of speakers: \n",
    "\"LANGUAGE\": use \"auto\" for automatic language identification or \"en\": \"english\", \"ca\": \"catalan\", \"nl\": \"dutch\", \"fi\": \"finnish\", \"fr\": \"french\", \"de\": \"german\", \"id\": \"indonesian\", \"it\": \"italian\", \"ja\": \"japanese\", \"ms\": \"malay\", \"no\": \"norwegian\", \"pl\": \"polish\", \"pt\": \"portuguese\", \"ru\": \"russian\", \"es\": \"spanish\", \"sv\": \"swedish\", \"tr\": \"turkish\", \"uk\": \"ukrainian\", \"vi\": \"vietnamese\".\n",
    "'NUM_SPEAKERS': use \"auto\" for automatic identification of speakers or write a specific number."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer = model.transformer(1, batch_transform_inference_instance_type, \n",
    "                                output_path=bucket+'/'+'<Your folder on S3 bucket where you want to store output audio>', accept = \"application/json\",\n",
    "                               max_payload=100, env={\"LANGUAGE\": \"en\", \"NUM_SPEAKERS\": \"2\"})\n",
    "transformer.transform(transform_input, content_type=batch_transform_content_type)\n",
    "transformer.wait()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visualize output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# output is available on following path\n",
    "transformer.output_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fs = s3fs.S3FileSystem()\n",
    "\n",
    "with fs.open(transformer.output_path+'/'+'<Name-of-the-audio-file>.wav.out', \"r\") as f:\n",
    "    output = f.read()\n",
    "output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Clean-up"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A. Delete the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.delete_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B. Unsubscribe to the listing (optional)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
